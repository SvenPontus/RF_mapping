{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc5...\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import deeplabcut\n",
    "import pandas as pd\n",
    "\n",
    "from dlchelperclass import DlcHelperClass as dhc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your project name\n",
    "project_name = ''\n",
    "# If you want to use labeled frames from an earlier project,\n",
    "# make sure to use the same experiment name as in the previous project.\n",
    "# Enter your experimenter name\n",
    "experimenter_name = ''\n",
    "# Specify where you want your project folder to be created\n",
    "work_dir = ''\n",
    "# create project path\n",
    "project_path = work_dir + '/' + project_name + '-' + experimenter_name + '-' + datetime.now().strftime(\"%Y-%m-%d\")\n",
    "# video path\n",
    "videos_dir_path = ''\n",
    "# Creates a list variable of all videos paths \n",
    "video_path = dhc.get_video_paths(path=videos_dir_path)\n",
    "# Create project\n",
    "deeplabcut.create_new_project(\n",
    "    project=project_name,\n",
    "    experimenter=experimenter_name,\n",
    "    videos=video_path,\n",
    "    working_directory=work_dir,\n",
    "    copy_videos=True\n",
    ")\n",
    "\n",
    "# Config yaml path\n",
    "config_path = project_path + '/config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize paths (For loading existing project)\n",
    "# skip this cell if you created a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your project path\n",
    "project_path = ''\n",
    "# Creates path for config file and videos\n",
    "config_path, video_path = dhc.get_config_and_video_paths(project_path=project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frames for labeling, amount of images and train/test ratio defined in config.yaml\n",
    "\n",
    "# \"Do you want to extract (perhaps additional) frames for video:\" answer yes\n",
    "\n",
    "deeplabcut.extract_frames(config=config_path, mode='automatic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use napari for labeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates CSV and h5 files needed for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(config=config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates training_stats.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for plotting losses\n",
    "deeplabcut.evaluate_network(config_path, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes prediction on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new videos with the models predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates likelihood.txt file and loss/vall_loss plot\n",
    "dhc.save_mean_likelihood_to_file(project_path=project_path)\n",
    "dhc.plot_loss_to_png(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract outlier frames and re-labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(config=config_path,\n",
    "                                   shuffle=1,\n",
    "                                  automatic=True,\n",
    "                                  videos=video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the DeepLabCut GUI to manually correct labels\n",
    "# Launch the GUI to manually adjust labels on the extracted frames\n",
    "deeplabcut.refine_labels(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.merge_datasets(config=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new training dataset that includes the updated labels\n",
    "# This prepares the training files with the corrected labels for training\n",
    "deeplabcut.create_training_dataset(config=config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have run the following code line before:\n",
    "# * deeplabcut.analyze_videos(project_path, video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the updated dataset\n",
    "# Use transfer learning to improve the existing model with the new data\n",
    "deeplabcut.train_network(project_path, shuffle=1, displayiters=100, saveiters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-evaluate performance on the updated model\n",
    "# Analyze the videos again to check if model accuracy has improved after retraining\n",
    "deeplabcut.analyze_videos(project_path, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = ''\n",
    "\n",
    "deeplabcut.analyze_videos(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If several videos to predict with one model \n",
    "# Analyze and label videos and get h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict several videos and models\n",
    "\n",
    "# your project folder path\n",
    "base_path = ''\n",
    "\n",
    "# your project folder from DLC there you have your .yaml file\n",
    "paths = [\n",
    "    '',\n",
    "]\n",
    "\n",
    "for path in paths:\n",
    "    project_path = base_path + path.strip()  \n",
    "    \n",
    "    config_path, video_path = dhc.get_config_and_video_paths(project_path=project_path)\n",
    "\n",
    "    # your folder there you have your video you want to predict\n",
    "    video_path = ''\n",
    "\n",
    "    # Assuming your videos have extensions like .mp4, .avi, etc.\n",
    "    video_extensions = ('*.mp4', '*.avi', '*.mkv')  # Add other extensions if needed\n",
    "    video_files = []\n",
    "\n",
    "    for ext in video_extensions:\n",
    "        video_files.extend(glob.glob(os.path.join(video_path, ext)))\n",
    "\n",
    "    for video_file in video_files:\n",
    "        # Analyze video    \n",
    "        deeplabcut.analyze_videos(config_path, video_file)\n",
    "        # Create labels\n",
    "        deeplabcut.create_labeled_video(config_path, videos=video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get likelihood from one predicted video printed out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your h5 file\n",
    "h5_path = ''\n",
    "df = pd.read_hdf(h5_path)\n",
    "df.columns = [f\"{bodypart}_{coord}\" for bodypart, coord in zip(df.columns.get_level_values(1), df.columns.get_level_values(2))]\n",
    "df_monofil = df.loc[:, df.columns.str.startswith(('FR', 'FG', 'FB')) & ~df.columns.str.endswith('likelihood')]\n",
    "df_square = df.loc[:, df.columns.str.startswith(('Top_left', 'Top_right', 'Bottom_left', 'Bottom_right')) & ~df.columns.str.endswith('likelihood')]\n",
    "df_likelihoods = df.loc[:, df.columns.str.endswith('likelihood')]\n",
    "overall_average = df_likelihoods.mean().mean()\n",
    "print(\"Overall Average Likelihood:\", overall_average)\n",
    "bodypart_means = df_likelihoods.mean(axis=0)\n",
    "print(\"Mean likelihood for each body part:\")\n",
    "print(bodypart_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood predicted Videos in txt file\n",
    "# Possible with several videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_h5_files(directory, output_file):\n",
    "    # Find all .h5 files in the specified directory\n",
    "    h5_files = glob.glob(os.path.join(directory, '*.h5'))\n",
    "    \n",
    "    total_sum = 0  # Initialize total sum of overall_average values\n",
    "    file_count = len(h5_files)  # Number of files processed\n",
    "    \n",
    "    with open(output_file, 'w') as f_out:\n",
    "        for h5_path in h5_files:\n",
    "            # Read the .h5 file into a DataFrame\n",
    "            df = pd.read_hdf(h5_path)\n",
    "            df.columns = [\n",
    "                f\"{bodypart}_{coord}\" \n",
    "                for bodypart, coord in zip(\n",
    "                    df.columns.get_level_values(1), \n",
    "                    df.columns.get_level_values(2)\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            # Select likelihood columns\n",
    "            df_likelihoods = df.loc[:, df.columns.str.endswith('likelihood')]\n",
    "            \n",
    "            # Calculate the overall average likelihood\n",
    "            overall_average = df_likelihoods.mean().mean()\n",
    "            \n",
    "            # Add overall_average to total_sum\n",
    "            total_sum += overall_average\n",
    "            \n",
    "            # Calculate the mean likelihood for each body part\n",
    "            bodypart_means = df_likelihoods.mean(axis=0)\n",
    "            \n",
    "            # Write the results to the output file\n",
    "            f_out.write(f\"File: {os.path.basename(h5_path)}\\n\")\n",
    "            f_out.write(f\"Overall Average Likelihood: {overall_average}\\n\")\n",
    "            f_out.write(\"Mean likelihood for each body part:\\n\")\n",
    "            f_out.write(bodypart_means.to_string())\n",
    "            f_out.write(\"\\n\")\n",
    "            f_out.write(\"-\" * 37 + \"\\n\")  # Separator line\n",
    "        \n",
    "        # Calculate the overall mean across all files\n",
    "        overall_mean = total_sum / file_count if file_count > 0 else 0\n",
    "        \n",
    "        # After processing all files, write only the overall mean\n",
    "        f_out.write(\"\\n\\n\\nOverall Mean of All Videos: {:.2f}\\n\".format(overall_mean))\n",
    "\n",
    "# Example usage:\n",
    "directory = ''  # Replace with your directory path\n",
    "output_file = 'likelihoods_predict.txt'\n",
    "process_h5_files(directory, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
